# Modelo-de-ML-para-Fraudes

# üîç Prevendo Fraudes com Regress√£o Log√≠stica

Este projeto simula uma entrevista t√©cnica para uma vaga de Cientista de Dados. O objetivo √© construir um modelo de Machine Learning capaz de prever fraudes com base em vari√°veis explicativas. A abordagem principal utiliza **regress√£o log√≠stica** com t√©cnicas de **balanceamento de classes** e **valida√ß√£o cruzada**.

---

## üìÅ Estrutura do Projeto

- `Introdu√ß√£o`: Contextualiza√ß√£o do problema e defini√ß√£o da vari√°vel alvo (`fraud`)
- `Pr√©-processamento`: Verifica√ß√£o de nulos, separa√ß√£o entre treino e teste, escalonamento
- `Balanceamento`: Aplica√ß√£o de SMOTE para equilibrar as classes
- `Modelagem`: Regress√£o log√≠stica com valida√ß√£o cruzada
- `Avalia√ß√£o`: M√©tricas como ROC AUC, precis√£o, recall e F1-score
- `Conclus√£o`: Interpreta√ß√£o dos resultados e pr√≥ximos passos

---

## üìä Dataset

- Fonte: `fraud_dataset.csv`
- Vari√°vel alvo: `fraud` (0 = n√£o fraude, 1 = fraude)
- Total de registros: 1.000.000
- Ap√≥s divis√£o:
  - Treino: 800.000 registros
  - Teste: 200.000 registros

---

## ‚öôÔ∏è T√©cnicas Utilizadas

- **Holdout**: Separa√ß√£o entre treino e teste com `train_test_split`
- **StandardScaler**: Escalonamento dos dados para evitar distor√ß√µes
- **SMOTE**: Oversampling da classe minorit√°ria para balanceamento
- **StratifiedKFold**: Valida√ß√£o cruzada estratificada
- **Regress√£o Log√≠stica**: Modelo base para classifica√ß√£o bin√°ria
- **M√©tricas**: `classification_report`, `roc_auc_score`, `cross_val_score`

---

## üìà Resultados

### Valida√ß√£o Cruzada (ROC AUC):
- M√©dia: `0.9792`

### Teste Final:
- ROC AUC: `0.9430`
- Acur√°cia: `93%`

### Relat√≥rio de Classifica√ß√£o:

| Classe | Precision | Recall | F1-score | Suporte |
|--------|-----------|--------|----------|---------|
| 0 (n√£o fraude) | 1.00 | 0.93 | 0.96 | 182.519 |
| 1 (fraude)     | 0.58 | 0.95 | 0.72 | 17.481  |

---

## üìå Conclus√£o

O modelo se mostrou eficaz em detectar fraudes, com **alta taxa de recall para a classe 1**, o que √© desej√°vel em cen√°rios onde √© melhor errar por excesso (falsos positivos) do que deixar fraudes passarem despercebidas. A precis√£o da classe 1 ainda pode ser otimizada com ajustes de threshold ou modelos mais robustos.

---

## üöÄ Pr√≥ximos Passos

- Testar modelos como Random Forest, XGBoost e LightGBM
- Ajustar o threshold de decis√£o para melhorar a precis√£o da classe 1
- Aplicar t√©cnicas de feature engineering para enriquecer os dados
- Avaliar com m√©tricas como Precision-Recall Curve e matriz de confus√£o visual

---

## üß† Autor

**Murilo Mike**  
Projeto desenvolvido como parte de estudos em Ci√™ncia de Dados e entrevistas t√©cnicas.

